{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /home/cosmopato/venv/bigdata/bin/pip: cannot execute: required file not found\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (19.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastparquet in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (2024.11.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from fastparquet) (2.2.3)\n",
      "Requirement already satisfied: numpy in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from fastparquet) (2.2.4)\n",
      "Requirement already satisfied: cramjam>=2.3 in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from fastparquet) (2.9.1)\n",
      "Requirement already satisfied: fsspec in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from fastparquet) (2025.3.2)\n",
      "Requirement already satisfied: packaging in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from fastparquet) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from scikit-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/cosmopato/venv/bigdata/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /home/cosmopato/venv/bigdata/bin/pip: cannot execute: required file not found\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/dilwong/flightprices?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 150M/5.51G [00:12<07:46, 12.4MB/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkagglehub\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Download latest version\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m path = \u001b[43mkagglehub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_download\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdilwong/flightprices\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPath to dataset files:\u001b[39m\u001b[33m\"\u001b[39m, path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/bigdata/lib/python3.12/site-packages/kagglehub/datasets.py:35\u001b[39m, in \u001b[36mdataset_download\u001b[39m\u001b[34m(handle, path, force_download)\u001b[39m\n\u001b[32m     33\u001b[39m h = parse_dataset_handle(handle)\n\u001b[32m     34\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh.to_url()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m, extra={**EXTRA_CONSOLE_BLOCK})\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m path, _ = \u001b[43mregistry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_resolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/bigdata/lib/python3.12/site-packages/kagglehub/registry.py:28\u001b[39m, in \u001b[36mMultiImplRegistry.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m._impls):\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m impl.is_supported(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     30\u001b[39m         fails.append(\u001b[38;5;28mtype\u001b[39m(impl).\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/bigdata/lib/python3.12/site-packages/kagglehub/resolver.py:29\u001b[39m, in \u001b[36mResolver.__call__\u001b[39m\u001b[34m(self, handle, path, force_download)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mself\u001b[39m, handle: T, path: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m, *, force_download: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     17\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Optional[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m     18\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Resolves a handle into a path with the requested file(s) and the resource's version number.\u001b[39;00m\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m \u001b[33;03m        Some cases where version number might be missing: Competition datasource, API-based models.\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     path, version = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_resolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[39;00m\n\u001b[32m     32\u001b[39m     register_datasource_access(handle, version)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/bigdata/lib/python3.12/site-packages/kagglehub/http_resolver.py:130\u001b[39m, in \u001b[36mDatasetHttpResolver._resolve\u001b[39m\u001b[34m(self, h, path, force_download)\u001b[39m\n\u001b[32m    127\u001b[39m os.makedirs(os.path.dirname(archive_path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# First, we download the archive.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchive_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m _extract_archive(archive_path, out_path)\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# Delete the archive\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/bigdata/lib/python3.12/site-packages/kagglehub/clients.py:216\u001b[39m, in \u001b[36mKaggleApiV1Client.download_file\u001b[39m\u001b[34m(self, path, out_file, resource_handle, cached_path, extract_auto_compressed_file)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[43m_download_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hash_object:\n\u001b[32m    219\u001b[39m     actual_md5_hash = to_b64_digest(hash_object)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/bigdata/lib/python3.12/site-packages/kagglehub/clients.py:275\u001b[39m, in \u001b[36m_download_file\u001b[39m\u001b[34m(response, out_file, size_read, total_size, hash_object)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total=total_size, initial=size_read, unit=\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m, unit_scale=\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor=\u001b[32m1024\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(out_file, open_mode) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhash_object\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/bigdata/lib/python3.12/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/bigdata/lib/python3.12/site-packages/urllib3/response.py:1066\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1069\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/bigdata/lib/python3.12/site-packages/urllib3/response.py:955\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    952\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    953\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    957\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/bigdata/lib/python3.12/site-packages/urllib3/response.py:879\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    876\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    882\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    887\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    888\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    889\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/bigdata/lib/python3.12/site-packages/urllib3/response.py:862\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"dilwong/flightprices\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DATASET_FILE = \"C:/Users/Pablo Cosmo/.cache/kagglehub/datasets/dilwong/flightprices/versions/1/itineraries.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Procesado chunk 0 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 1 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 2 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 3 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 4 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 5 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 6 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 7 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 8 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 9 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 10 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 11 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 12 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 13 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 14 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 15 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 16 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 17 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 18 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 19 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 20 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 21 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 22 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 23 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 24 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 25 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 26 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 27 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 28 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 29 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 30 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 31 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 32 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 33 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 34 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 35 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 36 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 37 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 38 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 39 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 40 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 41 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 42 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 43 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 44 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 45 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 46 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 47 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 48 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 49 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 50 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 51 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 52 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 53 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 54 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 55 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 56 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 57 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 58 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 59 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 60 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 61 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 62 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 63 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 64 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 65 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 66 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 67 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 68 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 69 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 70 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 71 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 72 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 73 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 74 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 75 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 76 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 77 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 78 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 79 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 80 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 81 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 82 - 138753 filas -> 13875 seleccionadas\n",
      "\n",
      "✅ Subset creado con 8213875 de 82138753 filas totales.\n"
     ]
    }
   ],
   "source": [
    "#CREAR SUBSET DEL 10%\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from subset_creator import create_random_subset_chunked\n",
    "\n",
    "DATASET_FILE = \"/home/nico_azcarate/.cache/kagglehub/datasets/dilwong/flightprices/versions/1/itineraries.csv\"\n",
    "SUBSET_PATH = \"../data_subsets/itineraries_subset.csv\"\n",
    "\n",
    "create_random_subset_chunked(DATASET_FILE, SUBSET_PATH, frac=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧼 Limpiando itinerarios...\n",
      "🔄 Procesando chunk 0 del subset...\n",
      "✅ Guardado chunk 0 con 999999 filas\n",
      "🔄 Procesando chunk 1 del subset...\n",
      "✅ Guardado chunk 1 con 1000000 filas\n",
      "🔄 Procesando chunk 2 del subset...\n",
      "✅ Guardado chunk 2 con 1000000 filas\n",
      "🔄 Procesando chunk 3 del subset...\n",
      "✅ Guardado chunk 3 con 1000000 filas\n",
      "🔄 Procesando chunk 4 del subset...\n",
      "✅ Guardado chunk 4 con 1000000 filas\n",
      "🔄 Procesando chunk 5 del subset...\n",
      "✅ Guardado chunk 5 con 1000000 filas\n",
      "🔄 Procesando chunk 6 del subset...\n",
      "✅ Guardado chunk 6 con 999999 filas\n",
      "🔄 Procesando chunk 7 del subset...\n",
      "✅ Guardado chunk 7 con 999999 filas\n",
      "🔄 Procesando chunk 8 del subset...\n",
      "✅ Guardado chunk 8 con 213873 filas\n"
     ]
    }
   ],
   "source": [
    "#CREAR  cleaned_chunks \n",
    "from clean_subset_chunks import run_clean_subset_pipeline\n",
    "\n",
    "print(\"🧼 Limpiando itinerarios...\")\n",
    "SUBSET_PATH = \"../data_subsets/itineraries_subset.csv\"\n",
    "run_clean_subset_pipeline(SUBSET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✈️ Extrayendo segmentos...\n",
      "✈️ Extrayendo segmentos del chunk 0...\n",
      "✅ Segment chunk 0 guardado con 17843677 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 1...\n",
      "✅ Segment chunk 1 guardado con 17853033 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 2...\n",
      "✅ Segment chunk 2 guardado con 17909538 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 3...\n",
      "✅ Segment chunk 3 guardado con 18153823 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 4...\n",
      "✅ Segment chunk 4 guardado con 18274042 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 5...\n",
      "✅ Segment chunk 5 guardado con 18685718 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 6...\n",
      "✅ Segment chunk 6 guardado con 18783314 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 7...\n",
      "✅ Segment chunk 7 guardado con 18703006 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 8...\n",
      "✅ Segment chunk 8 guardado con 3990873 segmentos\n"
     ]
    }
   ],
   "source": [
    "#SEPARAR SEGMENTOS\n",
    "from explode_segments import run_segment_extraction\n",
    "print(\"✈️ Extrayendo segmentos...\")\n",
    "run_segment_extraction(DATASET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✈️ Extrayendo segmentos con labels del subset...\n",
      "🔍 Primera pasada: recopilando categorías únicas...\n",
      "⚙️ Segunda pasada: explotando y codificando segmentos...\n",
      "✈️ Etiquetando segmentos del chunk 0...\n",
      "Procesando fila 0 del chunk 0...\n",
      "Procesando fila 100000 del chunk 0...\n",
      "Procesando fila 200000 del chunk 0...\n",
      "Procesando fila 300000 del chunk 0...\n",
      "Procesando fila 400000 del chunk 0...\n",
      "Procesando fila 500000 del chunk 0...\n",
      "Procesando fila 600000 del chunk 0...\n",
      "Procesando fila 700000 del chunk 0...\n",
      "Procesando fila 800000 del chunk 0...\n",
      "Procesando fila 900000 del chunk 0...\n",
      "✅ Segment chunk 0 guardado con 1784724 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 1...\n",
      "Procesando fila 0 del chunk 1...\n",
      "Procesando fila 100000 del chunk 1...\n",
      "Procesando fila 200000 del chunk 1...\n",
      "Procesando fila 300000 del chunk 1...\n",
      "Procesando fila 400000 del chunk 1...\n",
      "Procesando fila 500000 del chunk 1...\n",
      "Procesando fila 600000 del chunk 1...\n",
      "Procesando fila 700000 del chunk 1...\n",
      "Procesando fila 800000 del chunk 1...\n",
      "Procesando fila 900000 del chunk 1...\n",
      "✅ Segment chunk 1 guardado con 1786122 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 2...\n",
      "Procesando fila 0 del chunk 2...\n",
      "Procesando fila 100000 del chunk 2...\n",
      "Procesando fila 200000 del chunk 2...\n",
      "Procesando fila 300000 del chunk 2...\n",
      "Procesando fila 400000 del chunk 2...\n",
      "Procesando fila 500000 del chunk 2...\n",
      "Procesando fila 600000 del chunk 2...\n",
      "Procesando fila 700000 del chunk 2...\n",
      "Procesando fila 800000 del chunk 2...\n",
      "Procesando fila 900000 del chunk 2...\n",
      "✅ Segment chunk 2 guardado con 1790916 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 3...\n",
      "Procesando fila 0 del chunk 3...\n",
      "Procesando fila 100000 del chunk 3...\n",
      "Procesando fila 200000 del chunk 3...\n",
      "Procesando fila 300000 del chunk 3...\n",
      "Procesando fila 400000 del chunk 3...\n",
      "Procesando fila 500000 del chunk 3...\n",
      "Procesando fila 600000 del chunk 3...\n",
      "Procesando fila 700000 del chunk 3...\n",
      "Procesando fila 800000 del chunk 3...\n",
      "Procesando fila 900000 del chunk 3...\n",
      "✅ Segment chunk 3 guardado con 1815122 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 4...\n",
      "Procesando fila 0 del chunk 4...\n",
      "Procesando fila 100000 del chunk 4...\n",
      "Procesando fila 200000 del chunk 4...\n",
      "Procesando fila 300000 del chunk 4...\n",
      "Procesando fila 400000 del chunk 4...\n",
      "Procesando fila 500000 del chunk 4...\n",
      "Procesando fila 600000 del chunk 4...\n",
      "Procesando fila 700000 del chunk 4...\n",
      "Procesando fila 800000 del chunk 4...\n",
      "Procesando fila 900000 del chunk 4...\n",
      "✅ Segment chunk 4 guardado con 1827237 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 5...\n",
      "Procesando fila 0 del chunk 5...\n",
      "Procesando fila 100000 del chunk 5...\n",
      "Procesando fila 200000 del chunk 5...\n",
      "Procesando fila 300000 del chunk 5...\n",
      "Procesando fila 400000 del chunk 5...\n",
      "Procesando fila 500000 del chunk 5...\n",
      "Procesando fila 600000 del chunk 5...\n",
      "Procesando fila 700000 del chunk 5...\n",
      "Procesando fila 800000 del chunk 5...\n",
      "Procesando fila 900000 del chunk 5...\n",
      "✅ Segment chunk 5 guardado con 1869462 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 6...\n",
      "Procesando fila 0 del chunk 6...\n",
      "Procesando fila 100000 del chunk 6...\n",
      "Procesando fila 200000 del chunk 6...\n",
      "Procesando fila 300000 del chunk 6...\n",
      "Procesando fila 400000 del chunk 6...\n",
      "Procesando fila 500000 del chunk 6...\n",
      "Procesando fila 600000 del chunk 6...\n",
      "Procesando fila 700000 del chunk 6...\n",
      "Procesando fila 800000 del chunk 6...\n",
      "Procesando fila 900000 del chunk 6...\n",
      "✅ Segment chunk 6 guardado con 1878959 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 7...\n",
      "Procesando fila 0 del chunk 7...\n",
      "Procesando fila 100000 del chunk 7...\n",
      "Procesando fila 200000 del chunk 7...\n",
      "Procesando fila 300000 del chunk 7...\n",
      "Procesando fila 400000 del chunk 7...\n",
      "Procesando fila 500000 del chunk 7...\n",
      "Procesando fila 600000 del chunk 7...\n",
      "Procesando fila 700000 del chunk 7...\n",
      "Procesando fila 800000 del chunk 7...\n",
      "Procesando fila 900000 del chunk 7...\n",
      "✅ Segment chunk 7 guardado con 1869705 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 8...\n",
      "Procesando fila 0 del chunk 8...\n",
      "Procesando fila 100000 del chunk 8...\n",
      "Procesando fila 200000 del chunk 8...\n",
      "✅ Segment chunk 8 guardado con 399284 segmentos\n"
     ]
    }
   ],
   "source": [
    "#CREAR cleaned_label_segments CHUNKS\n",
    "\n",
    "from label_segments import run_labeled_segment_extraction\n",
    "\n",
    "SUBSET_FILE = \"../data_subsets/itineraries_subset.csv\"\n",
    "print(\"✈️ Extrayendo segmentos con labels del subset...\")\n",
    "run_labeled_segment_extraction(SUBSET_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itinerarios procesados: 9 chunks\n",
      "Shape: (999999, 13)\n",
      "Columnas: ['legId', 'startingAirport', 'destinationAirport', 'fareBasisCode', 'isBasicEconomy', 'isRefundable', 'isNonStop', 'baseFare', 'totalFare', 'seatsRemaining', 'elapsedDays', 'days_in_advance', 'totalTravelDistance']\n",
      "\n",
      "Fila 2 del itinerario limpio:\n",
      "legId                  b7a7c798768db6400d8db954710fca9c\n",
      "startingAirport                                       4\n",
      "destinationAirport                                    0\n",
      "fareBasisCode                                      4239\n",
      "isBasicEconomy                                        1\n",
      "isRefundable                                          0\n",
      "isNonStop                                             1\n",
      "baseFare                                          110.7\n",
      "totalFare                                         133.6\n",
      "seatsRemaining                                        9\n",
      "elapsedDays                                           0\n",
      "days_in_advance                                      10\n",
      "totalTravelDistance                               725.0\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legId</th>\n",
       "      <th>startingAirport</th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>fareBasisCode</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>isRefundable</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>baseFare</th>\n",
       "      <th>totalFare</th>\n",
       "      <th>seatsRemaining</th>\n",
       "      <th>elapsedDays</th>\n",
       "      <th>days_in_advance</th>\n",
       "      <th>totalTravelDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe531c56903f83f1a2d3383441628f0e</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>305.12</td>\n",
       "      <td>342.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b7a7c798768db6400d8db954710fca9c</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4239</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110.70</td>\n",
       "      <td>133.6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34ce0d1c3179003092e7e3917a3a1af6</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>3196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>189.77</td>\n",
       "      <td>218.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e2c40269cc8cfaab2f7287e55462bbba</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>293.95</td>\n",
       "      <td>339.6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41874184ce4af2f1d3d5b6c741a22bd8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4221</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184.19</td>\n",
       "      <td>221.6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2674.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              legId  startingAirport  destinationAirport  \\\n",
       "0  fe531c56903f83f1a2d3383441628f0e                4                  11   \n",
       "1  b7a7c798768db6400d8db954710fca9c                4                   0   \n",
       "2  34ce0d1c3179003092e7e3917a3a1af6                9                  15   \n",
       "3  e2c40269cc8cfaab2f7287e55462bbba                3                  14   \n",
       "4  41874184ce4af2f1d3d5b6c741a22bd8                1                   9   \n",
       "\n",
       "   fareBasisCode  isBasicEconomy  isRefundable  isNonStop  baseFare  \\\n",
       "0           2101               0             0          1    305.12   \n",
       "1           4239               1             0          1    110.70   \n",
       "2           3196               0             0          1    189.77   \n",
       "3           3151               0             0          0    293.95   \n",
       "4           4221               1             0          0    184.19   \n",
       "\n",
       "   totalFare  seatsRemaining  elapsedDays  days_in_advance  \\\n",
       "0      342.6               7            0               41   \n",
       "1      133.6               9            0               10   \n",
       "2      218.6               7            0               54   \n",
       "3      339.6               9            0               47   \n",
       "4      221.6               9            0                7   \n",
       "\n",
       "   totalTravelDistance  \n",
       "0               1115.0  \n",
       "1                725.0  \n",
       "2                339.0  \n",
       "3               1671.0  \n",
       "4               2674.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#VIEW ITINERARY cleaned_chunks\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Buscar todos los archivos de itinerarios limpios en la carpeta de prueba\n",
    "chunks = sorted(glob.glob(\"../cleaned_chunks/chunk_*.parquet\"))\n",
    "\n",
    "print(f\"Itinerarios procesados: {len(chunks)} chunks\")\n",
    "\n",
    "# Cargar el primer archivo como muestra\n",
    "df = pd.read_parquet(chunks[0])\n",
    "\n",
    "# Mostrar información general\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"Columnas:\", df.columns.tolist())\n",
    "\n",
    "# Mostrar una fila específica (por ejemplo, la segunda)\n",
    "fila = df.iloc[1]\n",
    "print(\"\\nFila 2 del itinerario limpio:\")\n",
    "print(fila)\n",
    "\n",
    "# Ver más filas si deseas una tabla:\n",
    "display(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentos etiquetados procesados: 9 archivos\n",
      "Shape: (1784724, 11)\n",
      "Columnas: ['legId', 'segment_num', 'airline_code', 'aircraft_type', 'duration_seconds', 'distance_miles', 'departure_hour', 'departure_weekday', 'cabin', 'arr_airport', 'dep_airport']\n",
      "\n",
      "Fila 2 del segmento etiquetado:\n",
      "legId                b7a7c798768db6400d8db954710fca9c\n",
      "segment_num                                         0\n",
      "airline_code                                        7\n",
      "aircraft_type                                    17.0\n",
      "duration_seconds                               7380.0\n",
      "distance_miles                                  725.0\n",
      "departure_hour                                      8\n",
      "departure_weekday                                   1\n",
      "cabin                                               4\n",
      "arr_airport                                         1\n",
      "dep_airport                                         4\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legId</th>\n",
       "      <th>segment_num</th>\n",
       "      <th>airline_code</th>\n",
       "      <th>aircraft_type</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>distance_miles</th>\n",
       "      <th>departure_hour</th>\n",
       "      <th>departure_weekday</th>\n",
       "      <th>cabin</th>\n",
       "      <th>arr_airport</th>\n",
       "      <th>dep_airport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe531c56903f83f1a2d3383441628f0e</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10260.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b7a7c798768db6400d8db954710fca9c</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7380.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34ce0d1c3179003092e7e3917a3a1af6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e2c40269cc8cfaab2f7287e55462bbba</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6840.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e2c40269cc8cfaab2f7287e55462bbba</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              legId  segment_num  airline_code  aircraft_type  \\\n",
       "0  fe531c56903f83f1a2d3383441628f0e            0             5           18.0   \n",
       "1  b7a7c798768db6400d8db954710fca9c            0             7           17.0   \n",
       "2  34ce0d1c3179003092e7e3917a3a1af6            0             6           17.0   \n",
       "3  e2c40269cc8cfaab2f7287e55462bbba            0             7           18.0   \n",
       "4  e2c40269cc8cfaab2f7287e55462bbba            1             7           18.0   \n",
       "\n",
       "   duration_seconds  distance_miles  departure_hour  departure_weekday  cabin  \\\n",
       "0           10260.0          1115.0               7                  6      4   \n",
       "1            7380.0           725.0               8                  1      4   \n",
       "2            5040.0           339.0              17                  4      4   \n",
       "3            6840.0           693.0              14                  4      4   \n",
       "4            9120.0           978.0              19                  4      4   \n",
       "\n",
       "   arr_airport  dep_airport  \n",
       "0           13            4  \n",
       "1            1            4  \n",
       "2           19           12  \n",
       "3           13            4  \n",
       "4           16           13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#VIEW cleaned_label_segments\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Buscar todos los archivos de segmentos etiquetados\n",
    "chunks = sorted(glob.glob(\"../cleaned_label_segments/segment_chunk_*.parquet\"))\n",
    "\n",
    "print(f\"Segmentos etiquetados procesados: {len(chunks)} archivos\")\n",
    "\n",
    "# Cargar el primer archivo como muestra\n",
    "df = pd.read_parquet(chunks[0])\n",
    "\n",
    "# Mostrar información general\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"Columnas:\", df.columns.tolist())\n",
    "\n",
    "# Mostrar una fila específica (por ejemplo, la segunda)\n",
    "fila = df.iloc[1]\n",
    "print(\"\\nFila 2 del segmento etiquetado:\")\n",
    "print(fila)\n",
    "\n",
    "# Ver más filas como tabla\n",
    "display(df.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREAR SUBSET FINAL (UNIENDO ITINERARIOS Y SEGMENTS)\n",
    "\n",
    "# 1. Cargar todos los archivos de segmentos etiquetados y unirlos\n",
    "segment_files = sorted(glob.glob(\"../cleaned_label_segments/segment_chunk_*.parquet\"))\n",
    "segments = pd.concat([pd.read_parquet(f) for f in segment_files], ignore_index=True)\n",
    "print(f\"✅ Segmentos cargados: {segments.shape}\")\n",
    "\n",
    "# 2. Cargar todos los archivos de itinerarios limpios y unirlos\n",
    "chunk_files = sorted(glob.glob(\"../cleaned_chunks/chunk_*.parquet\"))\n",
    "chunks = pd.concat([pd.read_parquet(f) for f in chunk_files], ignore_index=True)\n",
    "print(f\"✅ Itinerarios cargados: {chunks.shape}\")\n",
    "\n",
    "# 3. Unir por legId\n",
    "final_dataset = pd.merge(segments, chunks, on=\"legId\", how=\"inner\")\n",
    "print(f\"✅ Dataset final unido: {final_dataset.shape}\")\n",
    "\n",
    "# 4. Guardar\n",
    "final_dataset.to_parquet(\"../final_dataset.parquet\", index=False)\n",
    "print(\"📦 Dataset final guardado en 'final_dataset.parquet'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Shape: (58406065, 23)\n",
      "🧩 Columnas: ['legId', 'segment_num', 'airline_code', 'aircraft_type', 'duration_seconds', 'distance_miles', 'departure_hour', 'departure_weekday', 'cabin', 'arr_airport', 'dep_airport', 'startingAirport', 'destinationAirport', 'fareBasisCode', 'isBasicEconomy', 'isRefundable', 'isNonStop', 'baseFare', 'totalFare', 'seatsRemaining', 'elapsedDays', 'days_in_advance', 'totalTravelDistance']\n",
      "\n",
      "📄 Fila 2 del dataset final:\n",
      "legId                  fe531c56903f83f1a2d3383441628f0e\n",
      "segment_num                                           0\n",
      "airline_code                                          5\n",
      "aircraft_type                                      18.0\n",
      "duration_seconds                                10260.0\n",
      "distance_miles                                   1115.0\n",
      "departure_hour                                        7\n",
      "departure_weekday                                     6\n",
      "cabin                                                 4\n",
      "arr_airport                                          13\n",
      "dep_airport                                           4\n",
      "startingAirport                                       4\n",
      "destinationAirport                                   11\n",
      "fareBasisCode                                      1088\n",
      "isBasicEconomy                                        0\n",
      "isRefundable                                          0\n",
      "isNonStop                                             1\n",
      "baseFare                                         404.65\n",
      "totalFare                                         449.6\n",
      "seatsRemaining                                        7\n",
      "elapsedDays                                           0\n",
      "days_in_advance                                      37\n",
      "totalTravelDistance                              1115.0\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legId</th>\n",
       "      <th>segment_num</th>\n",
       "      <th>airline_code</th>\n",
       "      <th>aircraft_type</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>distance_miles</th>\n",
       "      <th>departure_hour</th>\n",
       "      <th>departure_weekday</th>\n",
       "      <th>cabin</th>\n",
       "      <th>arr_airport</th>\n",
       "      <th>...</th>\n",
       "      <th>fareBasisCode</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>isRefundable</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>baseFare</th>\n",
       "      <th>totalFare</th>\n",
       "      <th>seatsRemaining</th>\n",
       "      <th>elapsedDays</th>\n",
       "      <th>days_in_advance</th>\n",
       "      <th>totalTravelDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe531c56903f83f1a2d3383441628f0e</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10260.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>2101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>305.12</td>\n",
       "      <td>342.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe531c56903f83f1a2d3383441628f0e</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10260.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>404.65</td>\n",
       "      <td>449.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe531c56903f83f1a2d3383441628f0e</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10260.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>227.91</td>\n",
       "      <td>259.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b7a7c798768db6400d8db954710fca9c</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7380.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4239</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110.70</td>\n",
       "      <td>133.6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b7a7c798768db6400d8db954710fca9c</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7380.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174.88</td>\n",
       "      <td>202.6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>725.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              legId  segment_num  airline_code  aircraft_type  \\\n",
       "0  fe531c56903f83f1a2d3383441628f0e            0             5           18.0   \n",
       "1  fe531c56903f83f1a2d3383441628f0e            0             5           18.0   \n",
       "2  fe531c56903f83f1a2d3383441628f0e            0             5           18.0   \n",
       "3  b7a7c798768db6400d8db954710fca9c            0             7           17.0   \n",
       "4  b7a7c798768db6400d8db954710fca9c            0             7           17.0   \n",
       "\n",
       "   duration_seconds  distance_miles  departure_hour  departure_weekday  cabin  \\\n",
       "0           10260.0          1115.0               7                  6      4   \n",
       "1           10260.0          1115.0               7                  6      4   \n",
       "2           10260.0          1115.0               7                  6      4   \n",
       "3            7380.0           725.0               8                  1      4   \n",
       "4            7380.0           725.0               8                  1      4   \n",
       "\n",
       "   arr_airport  ...  fareBasisCode  isBasicEconomy  isRefundable  isNonStop  \\\n",
       "0           13  ...           2101               0             0          1   \n",
       "1           13  ...           1088               0             0          1   \n",
       "2           13  ...           1562               0             0          1   \n",
       "3            1  ...           4239               1             0          1   \n",
       "4            1  ...           1586               0             0          1   \n",
       "\n",
       "   baseFare  totalFare  seatsRemaining  elapsedDays  days_in_advance  \\\n",
       "0    305.12      342.6               7            0               41   \n",
       "1    404.65      449.6               7            0               37   \n",
       "2    227.91      259.6               7            0                6   \n",
       "3    110.70      133.6               9            0               10   \n",
       "4    174.88      202.6               9            0                6   \n",
       "\n",
       "   totalTravelDistance  \n",
       "0               1115.0  \n",
       "1               1115.0  \n",
       "2               1115.0  \n",
       "3                725.0  \n",
       "4                725.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#VIEW DATASET FINAL\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta al dataset final guardado\n",
    "df = pd.read_parquet(\"../data_subsets/final_dataset.parquet\")\n",
    "\n",
    "# Mostrar info general\n",
    "print(f\"🔍 Shape: {df.shape}\")\n",
    "print(\"🧩 Columnas:\", df.columns.tolist())\n",
    "\n",
    "# Mostrar una fila específica (por ejemplo, la segunda)\n",
    "fila = df.iloc[1]\n",
    "print(\"\\n📄 Fila 2 del dataset final:\")\n",
    "print(fila)\n",
    "\n",
    "# Ver una pequeña tabla\n",
    "display(df.head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
