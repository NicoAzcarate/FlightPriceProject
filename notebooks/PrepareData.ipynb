{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kagglehub in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (0.3.11)\n",
      "Requirement already satisfied: packaging in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->kagglehub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->kagglehub) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from tqdm->kagglehub) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-19.0.1-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pyarrow-19.0.1-cp313-cp313-win_amd64.whl (25.2 MB)\n",
      "   ---------------------------------------- 0.0/25.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.4/25.2 MB 13.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 5.0/25.2 MB 13.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 7.9/25.2 MB 13.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.7/25.2 MB 13.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.6/25.2 MB 13.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.5/25.2 MB 13.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.1/25.2 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.0/25.2 MB 13.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.2 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.2/25.2 MB 13.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-19.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp313-cp313-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting pandas>=1.5.0 (from fastparquet)\n",
      "  Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy (from fastparquet)\n",
      "  Downloading numpy-2.2.4-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.9.1-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting fsspec (from fastparquet)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from fastparquet) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.5.0->fastparquet)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.5.0->fastparquet)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
      "Downloading fastparquet-2024.11.0-cp313-cp313-win_amd64.whl (673 kB)\n",
      "   ---------------------------------------- 0.0/673.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 673.3/673.3 kB 11.4 MB/s eta 0:00:00\n",
      "Downloading cramjam-2.9.1-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 13.4 MB/s eta 0:00:00\n",
      "Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.6/11.5 MB 14.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.5/11.5 MB 14.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.5 MB 14.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.5 MB 14.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 14.1 MB/s eta 0:00:00\n",
      "Downloading numpy-2.2.4-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.9/12.6 MB 14.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.8/12.6 MB 14.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.7/12.6 MB 14.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.6 MB 14.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 14.0 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, fsspec, cramjam, pandas, fastparquet\n",
      "Successfully installed cramjam-2.9.1 fastparquet-2024.11.0 fsspec-2025.3.2 numpy-2.2.4 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from scikit-learn) (2.2.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.6/11.1 MB 14.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.1 MB 14.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.1 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 13.9 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.9/41.0 MB 14.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 5.8/41.0 MB 14.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 8.4/41.0 MB 13.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.3/41.0 MB 13.8 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 14.2/41.0 MB 13.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 17.0/41.0 MB 13.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 20.2/41.0 MB 14.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 23.1/41.0 MB 13.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 26.0/41.0 MB 14.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.8/41.0 MB 14.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 32.0/41.0 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 34.9/41.0 MB 14.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.7/41.0 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 14.0 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp313-cp313-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp313-cp313-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.1.0-cp313-cp313-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pablo cosmo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 2.9/8.1 MB 16.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.3/8.1 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 16.2 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading contourpy-1.3.1-cp313-cp313-win_amd64.whl (220 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp313-cp313-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 16.9 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp313-cp313-win_amd64.whl (71 kB)\n",
      "Downloading pillow-11.1.0-cp313-cp313-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 14.6 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.1.0 pyparsing-3.2.3 seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo Cosmo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/dilwong/flightprices?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.51G/5.51G [07:30<00:00, 13.1MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Pablo Cosmo\\.cache\\kagglehub\\datasets\\dilwong\\flightprices\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"dilwong/flightprices\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DATASET_FILE = \"C:/Users/Pablo Cosmo/.cache/kagglehub/datasets/dilwong/flightprices/versions/1/itineraries.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo Cosmo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Procesado chunk 0 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 1 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 2 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 3 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 4 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 5 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 6 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 7 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 8 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 9 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 10 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 11 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 12 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 13 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 14 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 15 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 16 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 17 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 18 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 19 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 20 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 21 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 22 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 23 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 24 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 25 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 26 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 27 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 28 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 29 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 30 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 31 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 32 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 33 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 34 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 35 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 36 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 37 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 38 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 39 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 40 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 41 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 42 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 43 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 44 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 45 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 46 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 47 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 48 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 49 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 50 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 51 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 52 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 53 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 54 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 55 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 56 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 57 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 58 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 59 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 60 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 61 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 62 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 63 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 64 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 65 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 66 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 67 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 68 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 69 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 70 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 71 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 72 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 73 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 74 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 75 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 76 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 77 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 78 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 79 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 80 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 81 - 1000000 filas -> 100000 seleccionadas\n",
      "📦 Procesado chunk 82 - 138753 filas -> 13875 seleccionadas\n",
      "\n",
      "✅ Subset creado con 8213875 de 82138753 filas totales.\n"
     ]
    }
   ],
   "source": [
    "#CREAR SUBSET DEL 10%\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from subset_creator import create_random_subset_chunked\n",
    "\n",
    "DATASET_FILE = \"/home/nico_azcarate/.cache/kagglehub/datasets/dilwong/flightprices/versions/1/itineraries.csv\"\n",
    "SUBSET_PATH = \"../data_subsets/itineraries_subset.csv\"\n",
    "\n",
    "create_random_subset_chunked(DATASET_FILE, SUBSET_PATH, frac=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧼 Limpiando itinerarios...\n",
      "🔄 Procesando chunk 0 del subset...\n",
      "✅ Guardado chunk 0 con 999999 filas\n",
      "🔄 Procesando chunk 1 del subset...\n",
      "✅ Guardado chunk 1 con 1000000 filas\n",
      "🔄 Procesando chunk 2 del subset...\n",
      "✅ Guardado chunk 2 con 1000000 filas\n",
      "🔄 Procesando chunk 3 del subset...\n",
      "✅ Guardado chunk 3 con 1000000 filas\n",
      "🔄 Procesando chunk 4 del subset...\n",
      "✅ Guardado chunk 4 con 1000000 filas\n",
      "🔄 Procesando chunk 5 del subset...\n",
      "✅ Guardado chunk 5 con 1000000 filas\n",
      "🔄 Procesando chunk 6 del subset...\n",
      "✅ Guardado chunk 6 con 999999 filas\n",
      "🔄 Procesando chunk 7 del subset...\n",
      "✅ Guardado chunk 7 con 999999 filas\n",
      "🔄 Procesando chunk 8 del subset...\n",
      "✅ Guardado chunk 8 con 213873 filas\n"
     ]
    }
   ],
   "source": [
    "#CREAR  cleaned_chunks \n",
    "from clean_subset_chunks import run_clean_subset_pipeline\n",
    "\n",
    "print(\"🧼 Limpiando itinerarios...\")\n",
    "SUBSET_PATH = \"../data_subsets/itineraries_subset.csv\"\n",
    "run_clean_subset_pipeline(SUBSET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✈️ Extrayendo segmentos...\n",
      "✈️ Extrayendo segmentos del chunk 0...\n",
      "✅ Segment chunk 0 guardado con 17843677 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 1...\n",
      "✅ Segment chunk 1 guardado con 17853033 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 2...\n",
      "✅ Segment chunk 2 guardado con 17909538 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 3...\n",
      "✅ Segment chunk 3 guardado con 18153823 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 4...\n",
      "✅ Segment chunk 4 guardado con 18274042 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 5...\n",
      "✅ Segment chunk 5 guardado con 18685718 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 6...\n",
      "✅ Segment chunk 6 guardado con 18783314 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 7...\n",
      "✅ Segment chunk 7 guardado con 18703006 segmentos\n",
      "✈️ Extrayendo segmentos del chunk 8...\n",
      "✅ Segment chunk 8 guardado con 3990873 segmentos\n"
     ]
    }
   ],
   "source": [
    "#SEPARAR SEGMENTOS\n",
    "from explode_segments import run_segment_extraction\n",
    "print(\"✈️ Extrayendo segmentos...\")\n",
    "run_segment_extraction(DATASET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✈️ Extrayendo segmentos con labels del subset...\n",
      "🔍 Primera pasada: recopilando categorías únicas...\n",
      "⚙️ Segunda pasada: explotando y codificando segmentos...\n",
      "✈️ Etiquetando segmentos del chunk 0...\n",
      "Procesando fila 0 del chunk 0...\n",
      "Procesando fila 100000 del chunk 0...\n",
      "Procesando fila 200000 del chunk 0...\n",
      "Procesando fila 300000 del chunk 0...\n",
      "Procesando fila 400000 del chunk 0...\n",
      "Procesando fila 500000 del chunk 0...\n",
      "Procesando fila 600000 del chunk 0...\n",
      "Procesando fila 700000 del chunk 0...\n",
      "Procesando fila 800000 del chunk 0...\n",
      "Procesando fila 900000 del chunk 0...\n",
      "✅ Segment chunk 0 guardado con 1784724 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 1...\n",
      "Procesando fila 0 del chunk 1...\n",
      "Procesando fila 100000 del chunk 1...\n",
      "Procesando fila 200000 del chunk 1...\n",
      "Procesando fila 300000 del chunk 1...\n",
      "Procesando fila 400000 del chunk 1...\n",
      "Procesando fila 500000 del chunk 1...\n",
      "Procesando fila 600000 del chunk 1...\n",
      "Procesando fila 700000 del chunk 1...\n",
      "Procesando fila 800000 del chunk 1...\n",
      "Procesando fila 900000 del chunk 1...\n",
      "✅ Segment chunk 1 guardado con 1786122 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 2...\n",
      "Procesando fila 0 del chunk 2...\n",
      "Procesando fila 100000 del chunk 2...\n",
      "Procesando fila 200000 del chunk 2...\n",
      "Procesando fila 300000 del chunk 2...\n",
      "Procesando fila 400000 del chunk 2...\n",
      "Procesando fila 500000 del chunk 2...\n",
      "Procesando fila 600000 del chunk 2...\n",
      "Procesando fila 700000 del chunk 2...\n",
      "Procesando fila 800000 del chunk 2...\n",
      "Procesando fila 900000 del chunk 2...\n",
      "✅ Segment chunk 2 guardado con 1790916 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 3...\n",
      "Procesando fila 0 del chunk 3...\n",
      "Procesando fila 100000 del chunk 3...\n",
      "Procesando fila 200000 del chunk 3...\n",
      "Procesando fila 300000 del chunk 3...\n",
      "Procesando fila 400000 del chunk 3...\n",
      "Procesando fila 500000 del chunk 3...\n",
      "Procesando fila 600000 del chunk 3...\n",
      "Procesando fila 700000 del chunk 3...\n",
      "Procesando fila 800000 del chunk 3...\n",
      "Procesando fila 900000 del chunk 3...\n",
      "✅ Segment chunk 3 guardado con 1815122 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 4...\n",
      "Procesando fila 0 del chunk 4...\n",
      "Procesando fila 100000 del chunk 4...\n",
      "Procesando fila 200000 del chunk 4...\n",
      "Procesando fila 300000 del chunk 4...\n",
      "Procesando fila 400000 del chunk 4...\n",
      "Procesando fila 500000 del chunk 4...\n",
      "Procesando fila 600000 del chunk 4...\n",
      "Procesando fila 700000 del chunk 4...\n",
      "Procesando fila 800000 del chunk 4...\n",
      "Procesando fila 900000 del chunk 4...\n",
      "✅ Segment chunk 4 guardado con 1827237 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 5...\n",
      "Procesando fila 0 del chunk 5...\n",
      "Procesando fila 100000 del chunk 5...\n",
      "Procesando fila 200000 del chunk 5...\n",
      "Procesando fila 300000 del chunk 5...\n",
      "Procesando fila 400000 del chunk 5...\n",
      "Procesando fila 500000 del chunk 5...\n",
      "Procesando fila 600000 del chunk 5...\n",
      "Procesando fila 700000 del chunk 5...\n",
      "Procesando fila 800000 del chunk 5...\n",
      "Procesando fila 900000 del chunk 5...\n",
      "✅ Segment chunk 5 guardado con 1869462 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 6...\n",
      "Procesando fila 0 del chunk 6...\n",
      "Procesando fila 100000 del chunk 6...\n",
      "Procesando fila 200000 del chunk 6...\n",
      "Procesando fila 300000 del chunk 6...\n",
      "Procesando fila 400000 del chunk 6...\n",
      "Procesando fila 500000 del chunk 6...\n",
      "Procesando fila 600000 del chunk 6...\n",
      "Procesando fila 700000 del chunk 6...\n",
      "Procesando fila 800000 del chunk 6...\n",
      "Procesando fila 900000 del chunk 6...\n",
      "✅ Segment chunk 6 guardado con 1878959 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 7...\n",
      "Procesando fila 0 del chunk 7...\n",
      "Procesando fila 100000 del chunk 7...\n",
      "Procesando fila 200000 del chunk 7...\n",
      "Procesando fila 300000 del chunk 7...\n",
      "Procesando fila 400000 del chunk 7...\n",
      "Procesando fila 500000 del chunk 7...\n",
      "Procesando fila 600000 del chunk 7...\n",
      "Procesando fila 700000 del chunk 7...\n",
      "Procesando fila 800000 del chunk 7...\n",
      "Procesando fila 900000 del chunk 7...\n",
      "✅ Segment chunk 7 guardado con 1869705 segmentos\n",
      "✈️ Etiquetando segmentos del chunk 8...\n",
      "Procesando fila 0 del chunk 8...\n",
      "Procesando fila 100000 del chunk 8...\n",
      "Procesando fila 200000 del chunk 8...\n",
      "✅ Segment chunk 8 guardado con 399284 segmentos\n"
     ]
    }
   ],
   "source": [
    "#CREAR cleaned_label_segments CHUNKS\n",
    "\n",
    "from label_segments import run_labeled_segment_extraction\n",
    "\n",
    "SUBSET_FILE = \"../data_subsets/itineraries_subset.csv\"\n",
    "print(\"✈️ Extrayendo segmentos con labels del subset...\")\n",
    "run_labeled_segment_extraction(SUBSET_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itinerarios procesados: 9 chunks\n",
      "Shape: (999999, 13)\n",
      "Columnas: ['legId', 'startingAirport', 'destinationAirport', 'fareBasisCode', 'isBasicEconomy', 'isRefundable', 'isNonStop', 'baseFare', 'totalFare', 'seatsRemaining', 'elapsedDays', 'days_in_advance', 'totalTravelDistance']\n",
      "\n",
      "Fila 2 del itinerario limpio:\n",
      "legId                  b7a7c798768db6400d8db954710fca9c\n",
      "startingAirport                                       4\n",
      "destinationAirport                                    0\n",
      "fareBasisCode                                      4239\n",
      "isBasicEconomy                                        1\n",
      "isRefundable                                          0\n",
      "isNonStop                                             1\n",
      "baseFare                                          110.7\n",
      "totalFare                                         133.6\n",
      "seatsRemaining                                        9\n",
      "elapsedDays                                           0\n",
      "days_in_advance                                      10\n",
      "totalTravelDistance                               725.0\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legId</th>\n",
       "      <th>startingAirport</th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>fareBasisCode</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>isRefundable</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>baseFare</th>\n",
       "      <th>totalFare</th>\n",
       "      <th>seatsRemaining</th>\n",
       "      <th>elapsedDays</th>\n",
       "      <th>days_in_advance</th>\n",
       "      <th>totalTravelDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe531c56903f83f1a2d3383441628f0e</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>305.12</td>\n",
       "      <td>342.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b7a7c798768db6400d8db954710fca9c</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4239</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110.70</td>\n",
       "      <td>133.6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34ce0d1c3179003092e7e3917a3a1af6</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>3196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>189.77</td>\n",
       "      <td>218.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e2c40269cc8cfaab2f7287e55462bbba</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>293.95</td>\n",
       "      <td>339.6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41874184ce4af2f1d3d5b6c741a22bd8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4221</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184.19</td>\n",
       "      <td>221.6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2674.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              legId  startingAirport  destinationAirport  \\\n",
       "0  fe531c56903f83f1a2d3383441628f0e                4                  11   \n",
       "1  b7a7c798768db6400d8db954710fca9c                4                   0   \n",
       "2  34ce0d1c3179003092e7e3917a3a1af6                9                  15   \n",
       "3  e2c40269cc8cfaab2f7287e55462bbba                3                  14   \n",
       "4  41874184ce4af2f1d3d5b6c741a22bd8                1                   9   \n",
       "\n",
       "   fareBasisCode  isBasicEconomy  isRefundable  isNonStop  baseFare  \\\n",
       "0           2101               0             0          1    305.12   \n",
       "1           4239               1             0          1    110.70   \n",
       "2           3196               0             0          1    189.77   \n",
       "3           3151               0             0          0    293.95   \n",
       "4           4221               1             0          0    184.19   \n",
       "\n",
       "   totalFare  seatsRemaining  elapsedDays  days_in_advance  \\\n",
       "0      342.6               7            0               41   \n",
       "1      133.6               9            0               10   \n",
       "2      218.6               7            0               54   \n",
       "3      339.6               9            0               47   \n",
       "4      221.6               9            0                7   \n",
       "\n",
       "   totalTravelDistance  \n",
       "0               1115.0  \n",
       "1                725.0  \n",
       "2                339.0  \n",
       "3               1671.0  \n",
       "4               2674.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#VIEW ITINERARY cleaned_chunks\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Buscar todos los archivos de itinerarios limpios en la carpeta de prueba\n",
    "chunks = sorted(glob.glob(\"../cleaned_chunks/chunk_*.parquet\"))\n",
    "\n",
    "print(f\"Itinerarios procesados: {len(chunks)} chunks\")\n",
    "\n",
    "# Cargar el primer archivo como muestra\n",
    "df = pd.read_parquet(chunks[0])\n",
    "\n",
    "# Mostrar información general\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"Columnas:\", df.columns.tolist())\n",
    "\n",
    "# Mostrar una fila específica (por ejemplo, la segunda)\n",
    "fila = df.iloc[1]\n",
    "print(\"\\nFila 2 del itinerario limpio:\")\n",
    "print(fila)\n",
    "\n",
    "# Ver más filas si deseas una tabla:\n",
    "display(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentos etiquetados procesados: 9 archivos\n",
      "Shape: (1784724, 11)\n",
      "Columnas: ['legId', 'segment_num', 'airline_code', 'aircraft_type', 'duration_seconds', 'distance_miles', 'departure_hour', 'departure_weekday', 'cabin', 'arr_airport', 'dep_airport']\n",
      "\n",
      "Fila 2 del segmento etiquetado:\n",
      "legId                b7a7c798768db6400d8db954710fca9c\n",
      "segment_num                                         0\n",
      "airline_code                                        7\n",
      "aircraft_type                                    17.0\n",
      "duration_seconds                               7380.0\n",
      "distance_miles                                  725.0\n",
      "departure_hour                                      8\n",
      "departure_weekday                                   1\n",
      "cabin                                               4\n",
      "arr_airport                                         1\n",
      "dep_airport                                         4\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legId</th>\n",
       "      <th>segment_num</th>\n",
       "      <th>airline_code</th>\n",
       "      <th>aircraft_type</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>distance_miles</th>\n",
       "      <th>departure_hour</th>\n",
       "      <th>departure_weekday</th>\n",
       "      <th>cabin</th>\n",
       "      <th>arr_airport</th>\n",
       "      <th>dep_airport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe531c56903f83f1a2d3383441628f0e</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10260.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b7a7c798768db6400d8db954710fca9c</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7380.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34ce0d1c3179003092e7e3917a3a1af6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e2c40269cc8cfaab2f7287e55462bbba</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6840.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e2c40269cc8cfaab2f7287e55462bbba</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              legId  segment_num  airline_code  aircraft_type  \\\n",
       "0  fe531c56903f83f1a2d3383441628f0e            0             5           18.0   \n",
       "1  b7a7c798768db6400d8db954710fca9c            0             7           17.0   \n",
       "2  34ce0d1c3179003092e7e3917a3a1af6            0             6           17.0   \n",
       "3  e2c40269cc8cfaab2f7287e55462bbba            0             7           18.0   \n",
       "4  e2c40269cc8cfaab2f7287e55462bbba            1             7           18.0   \n",
       "\n",
       "   duration_seconds  distance_miles  departure_hour  departure_weekday  cabin  \\\n",
       "0           10260.0          1115.0               7                  6      4   \n",
       "1            7380.0           725.0               8                  1      4   \n",
       "2            5040.0           339.0              17                  4      4   \n",
       "3            6840.0           693.0              14                  4      4   \n",
       "4            9120.0           978.0              19                  4      4   \n",
       "\n",
       "   arr_airport  dep_airport  \n",
       "0           13            4  \n",
       "1            1            4  \n",
       "2           19           12  \n",
       "3           13            4  \n",
       "4           16           13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#VIEW cleaned_label_segments\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Buscar todos los archivos de segmentos etiquetados\n",
    "chunks = sorted(glob.glob(\"../cleaned_label_segments/segment_chunk_*.parquet\"))\n",
    "\n",
    "print(f\"Segmentos etiquetados procesados: {len(chunks)} archivos\")\n",
    "\n",
    "# Cargar el primer archivo como muestra\n",
    "df = pd.read_parquet(chunks[0])\n",
    "\n",
    "# Mostrar información general\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"Columnas:\", df.columns.tolist())\n",
    "\n",
    "# Mostrar una fila específica (por ejemplo, la segunda)\n",
    "fila = df.iloc[1]\n",
    "print(\"\\nFila 2 del segmento etiquetado:\")\n",
    "print(fila)\n",
    "\n",
    "# Ver más filas como tabla\n",
    "display(df.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREAR SUBSET FINAL (UNIENDO ITINERARIOS Y SEGMENTS)\n",
    "\n",
    "# 1. Cargar todos los archivos de segmentos etiquetados y unirlos\n",
    "segment_files = sorted(glob.glob(\"../cleaned_label_segments/segment_chunk_*.parquet\"))\n",
    "segments = pd.concat([pd.read_parquet(f) for f in segment_files], ignore_index=True)\n",
    "print(f\"✅ Segmentos cargados: {segments.shape}\")\n",
    "\n",
    "# 2. Cargar todos los archivos de itinerarios limpios y unirlos\n",
    "chunk_files = sorted(glob.glob(\"../cleaned_chunks/chunk_*.parquet\"))\n",
    "chunks = pd.concat([pd.read_parquet(f) for f in chunk_files], ignore_index=True)\n",
    "print(f\"✅ Itinerarios cargados: {chunks.shape}\")\n",
    "\n",
    "# 3. Unir por legId\n",
    "final_dataset = pd.merge(segments, chunks, on=\"legId\", how=\"inner\")\n",
    "print(f\"✅ Dataset final unido: {final_dataset.shape}\")\n",
    "\n",
    "# 4. Guardar\n",
    "final_dataset.to_parquet(\"../final_dataset.parquet\", index=False)\n",
    "print(\"📦 Dataset final guardado en 'final_dataset.parquet'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Shape: (58406065, 23)\n",
      "🧩 Columnas: ['legId', 'segment_num', 'airline_code', 'aircraft_type', 'duration_seconds', 'distance_miles', 'departure_hour', 'departure_weekday', 'cabin', 'arr_airport', 'dep_airport', 'startingAirport', 'destinationAirport', 'fareBasisCode', 'isBasicEconomy', 'isRefundable', 'isNonStop', 'baseFare', 'totalFare', 'seatsRemaining', 'elapsedDays', 'days_in_advance', 'totalTravelDistance']\n",
      "\n",
      "📄 Fila 2 del dataset final:\n",
      "legId                  fe531c56903f83f1a2d3383441628f0e\n",
      "segment_num                                           0\n",
      "airline_code                                          5\n",
      "aircraft_type                                      18.0\n",
      "duration_seconds                                10260.0\n",
      "distance_miles                                   1115.0\n",
      "departure_hour                                        7\n",
      "departure_weekday                                     6\n",
      "cabin                                                 4\n",
      "arr_airport                                          13\n",
      "dep_airport                                           4\n",
      "startingAirport                                       4\n",
      "destinationAirport                                   11\n",
      "fareBasisCode                                      1088\n",
      "isBasicEconomy                                        0\n",
      "isRefundable                                          0\n",
      "isNonStop                                             1\n",
      "baseFare                                         404.65\n",
      "totalFare                                         449.6\n",
      "seatsRemaining                                        7\n",
      "elapsedDays                                           0\n",
      "days_in_advance                                      37\n",
      "totalTravelDistance                              1115.0\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legId</th>\n",
       "      <th>segment_num</th>\n",
       "      <th>airline_code</th>\n",
       "      <th>aircraft_type</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>distance_miles</th>\n",
       "      <th>departure_hour</th>\n",
       "      <th>departure_weekday</th>\n",
       "      <th>cabin</th>\n",
       "      <th>arr_airport</th>\n",
       "      <th>...</th>\n",
       "      <th>fareBasisCode</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>isRefundable</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>baseFare</th>\n",
       "      <th>totalFare</th>\n",
       "      <th>seatsRemaining</th>\n",
       "      <th>elapsedDays</th>\n",
       "      <th>days_in_advance</th>\n",
       "      <th>totalTravelDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe531c56903f83f1a2d3383441628f0e</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10260.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>2101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>305.12</td>\n",
       "      <td>342.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe531c56903f83f1a2d3383441628f0e</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10260.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>404.65</td>\n",
       "      <td>449.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe531c56903f83f1a2d3383441628f0e</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10260.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>227.91</td>\n",
       "      <td>259.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b7a7c798768db6400d8db954710fca9c</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7380.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4239</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110.70</td>\n",
       "      <td>133.6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b7a7c798768db6400d8db954710fca9c</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7380.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174.88</td>\n",
       "      <td>202.6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>725.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              legId  segment_num  airline_code  aircraft_type  \\\n",
       "0  fe531c56903f83f1a2d3383441628f0e            0             5           18.0   \n",
       "1  fe531c56903f83f1a2d3383441628f0e            0             5           18.0   \n",
       "2  fe531c56903f83f1a2d3383441628f0e            0             5           18.0   \n",
       "3  b7a7c798768db6400d8db954710fca9c            0             7           17.0   \n",
       "4  b7a7c798768db6400d8db954710fca9c            0             7           17.0   \n",
       "\n",
       "   duration_seconds  distance_miles  departure_hour  departure_weekday  cabin  \\\n",
       "0           10260.0          1115.0               7                  6      4   \n",
       "1           10260.0          1115.0               7                  6      4   \n",
       "2           10260.0          1115.0               7                  6      4   \n",
       "3            7380.0           725.0               8                  1      4   \n",
       "4            7380.0           725.0               8                  1      4   \n",
       "\n",
       "   arr_airport  ...  fareBasisCode  isBasicEconomy  isRefundable  isNonStop  \\\n",
       "0           13  ...           2101               0             0          1   \n",
       "1           13  ...           1088               0             0          1   \n",
       "2           13  ...           1562               0             0          1   \n",
       "3            1  ...           4239               1             0          1   \n",
       "4            1  ...           1586               0             0          1   \n",
       "\n",
       "   baseFare  totalFare  seatsRemaining  elapsedDays  days_in_advance  \\\n",
       "0    305.12      342.6               7            0               41   \n",
       "1    404.65      449.6               7            0               37   \n",
       "2    227.91      259.6               7            0                6   \n",
       "3    110.70      133.6               9            0               10   \n",
       "4    174.88      202.6               9            0                6   \n",
       "\n",
       "   totalTravelDistance  \n",
       "0               1115.0  \n",
       "1               1115.0  \n",
       "2               1115.0  \n",
       "3                725.0  \n",
       "4                725.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#VIEW DATASET FINAL\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta al dataset final guardado\n",
    "df = pd.read_parquet(\"../data_subsets/final_dataset.parquet\")\n",
    "\n",
    "# Mostrar info general\n",
    "print(f\"🔍 Shape: {df.shape}\")\n",
    "print(\"🧩 Columnas:\", df.columns.tolist())\n",
    "\n",
    "# Mostrar una fila específica (por ejemplo, la segunda)\n",
    "fila = df.iloc[1]\n",
    "print(\"\\n📄 Fila 2 del dataset final:\")\n",
    "print(fila)\n",
    "\n",
    "# Ver una pequeña tabla\n",
    "display(df.head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
